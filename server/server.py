import os
import time
import uuid
import dotenv
import uvicorn
from fastapi import FastAPI, Request, HTTPException, status, Header
from pydantic import BaseModel, Field
from typing import List, Optional, Union, Dict, Any
from .main import load_model, generate_chat_response

dotenv.load_dotenv()

app = FastAPI(title="OpenAI-Compatible Chat API", version="1.0.0")

tokenizer, model = None, None
REQUIRED_TOKEN = os.environ.get("CHAT_BOT_API_KEY")
FRONTEND_URLS_STR = os.environ.get("FRONTEND_URLS", "")
ALLOWED_FRONTEND_URLS = [url.strip() for url in FRONTEND_URLS_STR.split(',') if url.strip()] if FRONTEND_URLS_STR else []

class ChatMessage(BaseModel):
    role: str = Field(..., description="æ¶ˆæ¯è§’è‰²: system, user, assistant")
    content: Union[str, List[Dict[str, Any]]] = Field(..., description="æ¶ˆæ¯å†…å®¹")

class ChatCompletionRequest(BaseModel):
    model: str = Field(default="qwen-3-1.7b", description="æ¨¡å‹åç§°")
    messages: List[ChatMessage] = Field(..., description="èŠå¤©æ¶ˆæ¯åˆ—è¡¨")
    max_tokens: Optional[int] = Field(512, ge=1, le=4096, description="æœ€å¤§ç”Ÿæˆtokenæ•°")
    temperature: Optional[float] = Field(0.7, ge=0.0, le=2.0, description="é‡‡æ ·æ¸©åº¦")
    top_p: Optional[float] = Field(0.8, ge=0.0, le=1.0, description="æ ¸é‡‡æ ·æ¦‚ç‡")
    top_k: Optional[int] = Field(20, ge=1, description="top-ké‡‡æ ·")
    frequency_penalty: Optional[float] = Field(0.0, ge=-2.0, le=2.0, description="é¢‘ç‡æƒ©ç½š")
    presence_penalty: Optional[float] = Field(0.0, ge=-2.0, le=2.0, description="å­˜åœ¨æƒ©ç½š")
    repetition_penalty: Optional[float] = Field(1.1, ge=0.1, le=2.0, description="é‡å¤æƒ©ç½š")
    stream: Optional[bool] = Field(False, description="æ˜¯å¦æµå¼è¾“å‡º")
    stop: Optional[Union[str, List[str]]] = Field(None, description="åœæ­¢æ ‡è®°")
    n: Optional[int] = Field(1, ge=1, le=1, description="ç”Ÿæˆé€‰æ‹©æ•°")
    logprobs: Optional[bool] = Field(False, description="æ˜¯å¦è¿”å›logprobs")
    echo: Optional[bool] = Field(False, description="æ˜¯å¦å›æ˜¾prompt")
    seed: Optional[int] = Field(None, description="éšæœºç§å­")
    user: Optional[str] = Field(None, description="ç”¨æˆ·æ ‡è¯†")

class ChatCompletionResponse(BaseModel):
    id: str
    object: str = "chat.completion"
    created: int
    model: str
    choices: List[Dict[str, Any]]
    usage: Dict[str, int]

class ErrorResponse(BaseModel):
    error: Dict[str, Any]

@app.on_event("startup")
def startup_event():
    global tokenizer, model
    print("æ­£åœ¨å¯åŠ¨ OpenAI å…¼å®¹èŠå¤©æœåŠ¡...")
    tokenizer, model = load_model()
    if tokenizer is None or model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
        exit(1)
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

def check_token(request: Request, authorization: Optional[str]):
    """
    éªŒè¯è¯·æ±‚çš„æ¥æºæˆ–Authorizationå¤´ä¸­çš„tokenã€‚

    éªŒè¯é€»è¾‘:
    1. å¦‚æœè¯·æ±‚çš„ 'origin' å¤´åœ¨ FRONTEND_URLS ç¯å¢ƒå˜é‡å®šä¹‰çš„ç™½åå•ä¸­ï¼Œåˆ™è·³è¿‡tokenéªŒè¯ã€‚
    2. å¦‚æœæœªè®¾ç½®ç™½åå•ï¼Œæˆ–æ¥æºä¸åœ¨ç™½åå•ä¸­ï¼Œåˆ™æ£€æŸ¥ CHAT_BOT_API_KEYã€‚
    3. å¦‚æœ CHAT_BOT_API_KEY æœªè®¾ç½®ï¼Œåˆ™è·³è¿‡tokenéªŒè¯ã€‚
    4. å¦‚æœä»¥ä¸Šæ¡ä»¶éƒ½ä¸æ»¡è¶³ï¼Œåˆ™å¿…é¡»æä¾›æœ‰æ•ˆçš„ Bearer tokenã€‚
    """
    origin = request.headers.get("origin")
    
    # 1. æ£€æŸ¥æ¥æºæ˜¯å¦åœ¨ç™½åå•ä¸­
    if origin and ALLOWED_FRONTEND_URLS and origin in ALLOWED_FRONTEND_URLS:
        print(f"INFO: è¯·æ±‚æ¥æº '{origin}' åœ¨ç™½åå•ä¸­ï¼Œè·³è¿‡TokenéªŒè¯ã€‚")
        return

    # 2. å¦‚æœæ¥æºä¸åœ¨ç™½åå•ï¼Œåˆ™å›é€€åˆ°tokenéªŒè¯
    if not REQUIRED_TOKEN:
        print("WARN: æœªè®¾ç½® CHAT_BOT_API_KEY ç¯å¢ƒå˜é‡ï¼Œæ‰€æœ‰éç™½åå•æ¥æºçš„è¯·æ±‚éƒ½å°†è¢«å…è®¸ã€‚")
        return
    
    if not authorization:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED, 
            detail="ç¼ºå°‘Authorizationå¤´"
        )
    
    if not authorization.startswith("Bearer "):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED, 
            detail="Authorizationæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º: Bearer <token>"
        )
    
    token = authorization.split(" ", 1)[1]
    if token != REQUIRED_TOKEN:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED, 
            detail="API Keyæ— æ•ˆ"
        )
    
    print("INFO: API KeyéªŒè¯æˆåŠŸã€‚")

@app.get("/")
async def root():
    return {"message": "OpenAI Compatible Chat API", "status": "running"}

@app.get("/api/v1/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    return {
        "object": "list",
        "data": [
            {
                "id": "Qwen3-1.7B_quantized",
                "object": "model",
                "created": int(time.time()),
                "owned_by": "local"
            }
        ]
    }

@app.post("/api/v1/chat", response_model=Union[ChatCompletionResponse, ErrorResponse])
async def create_chat_completion(payload: ChatCompletionRequest, request: Request, authorization: str = Header(None)):
    """å¤„ç†èŠå¤©è¯·æ±‚ï¼Œè¿”å›AIç”Ÿæˆçš„å®Œæ•´å›å¤ã€‚"""
    try:
        check_token(request, authorization)
        
        if tokenizer is None or model is None:
            raise HTTPException(status_code=500, detail="æ¨¡å‹æœªæ­£ç¡®åŠ è½½")
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        chat_messages = []
        
        # å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾› system promptï¼Œåˆ™æ·»åŠ ä¸€ä¸ªé»˜è®¤çš„
        if not payload.messages or payload.messages[0].role != "system":
            print("INFO: æœªæä¾› system promptï¼Œå°†æ·»åŠ é»˜è®¤å€¼ã€‚")
            chat_messages.append({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚"
            })
            
        for msg in payload.messages:
            chat_messages.append({
                "role": msg.role,
                "content": msg.content if isinstance(msg.content, str) else str(msg.content)
            })
        
        # è°ƒç”¨ç”Ÿæˆå‡½æ•°
        response_text = generate_chat_response(
            tokenizer=tokenizer,
            model=model,
            messages=chat_messages,
            max_tokens=payload.max_tokens or 512,
            temperature=payload.temperature or 0.7,
            top_p=payload.top_p or 0.8,
            top_k=payload.top_k,
            frequency_penalty=payload.frequency_penalty or 0.0,
            presence_penalty=payload.presence_penalty or 0.0,
            repetition_penalty=payload.repetition_penalty or 1.1,
            do_sample=(payload.temperature or 0.7) > 0
        )
        
        if response_text is None:
            raise HTTPException(status_code=500, detail="ç”Ÿæˆå›å¤å¤±è´¥")
        
        # æ„å»ºå“åº”
        completion_id = f"chatcmpl-{uuid.uuid4().hex[:24]}"
        created_time = int(time.time())
        
        # ç®€å•çš„tokenè®¡æ•°ä¼°ç®—
        prompt_tokens = sum(len(str(msg['content']).split()) for msg in chat_messages)
        completion_tokens = len(response_text.split())
        total_tokens = prompt_tokens + completion_tokens
        
        response = {
            "id": completion_id,
            "object": "chat.completion",
            "created": created_time,
            "model": payload.model,
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": response_text
                    },
                    "finish_reason": "stop"
                }
            ],
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            }
        }
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": tokenizer is not None and model is not None,
        "timestamp": int(time.time())
    }

def main():
    print("ğŸš€ å¯åŠ¨ AI èŠå¤©æœåŠ¡...")
    print("ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ”— ä¸»è¦èŠå¤©æ¥å£: http://localhost:8000/api/v1/chat")
    uvicorn.run("chat_bot_model.server:app", host="0.0.0.0", port=8000, reload=False)

if __name__ == "__main__":
    main() 